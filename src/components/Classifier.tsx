//src/components/Classifier.tsx

import React, { useState, useEffect, useCallback } from 'react';

const GEMINI_API_KEY = import.meta.env.VITE_GEMINI_API_KEY;
const GEMINI_API_URL = import.meta.env.VITE_GEMINI_API_URL;

const MAX_REQUESTS = 30;
const COOLDOWN_MS = 10 * 1000;

const getTrashImage = (text: string): string | null => {
  const lower = text.toLowerCase();
  if (lower.includes('jaune')) return '/poubelle-jaune.png';
  if (lower.includes('verte')) return '/poubelle-verte.png';
  if (lower.includes('marron')) return '/poubelle-marron.png';
  if (lower.includes('grise')) return '/poubelle-grise.png';
  return null;
};

const SUGGESTIONS = [
  "Bouteille de shampoing",
  "Carton de pizza",
  "Canette de soda",
  "Bouteille en verre",
  "Sac plastique",
  "Pot de yaourt"
];

const Classifier: React.FC = () => {
  const [input, setInput] = useState('');
  const [response, setResponse] = useState('');
  const [trashImage, setTrashImage] = useState<string | null>(null);
  const [loading, setLoading] = useState(false);
  const [lastCall, setLastCall] = useState<number | null>(null);
  const [requestCount, setRequestCount] = useState<number>(0);
  const [history, setHistory] = useState<{ object: string; result: string }[]>([]);
  const [darkMode, setDarkMode] = useState<boolean>(false);
  const [canSpeak, setCanSpeak] = useState(false);

  // Fonction utilitaire pour attendre que les voix soient disponibles
  const waitForVoices = (): Promise<SpeechSynthesisVoice[]> => {
    return new Promise((resolve) => {
      let voices = speechSynthesis.getVoices();
      if (voices.length) return resolve(voices);

      const interval = setInterval(() => {
        voices = speechSynthesis.getVoices();
        if (voices.length) {
          clearInterval(interval);
          resolve(voices);
        }
      }, 100);

      // Fallback apr√®s 2 secondes
      setTimeout(() => {
        clearInterval(interval);
        resolve(speechSynthesis.getVoices());
      }, 2000);
    });
  };

  // Fonction de lecture vocale
  const speak = async (text: string) => {
    const voices = await waitForVoices();
    const frVoice = voices.find(v => v.lang.startsWith("fr")) || voices[0];

    if (!frVoice) {
      alert("‚ùå Aucune voix disponible sur ce navigateur.");
      return;
    }

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.voice = frVoice;
    utterance.lang = frVoice.lang;

    speechSynthesis.cancel();
    // Un l√©ger d√©lai peut aider √† contourner certaines restrictions
    setTimeout(() => {
      speechSynthesis.speak(utterance);
      console.log("üîä Lecture d√©clench√©e avec :", frVoice.name);
    }, 150);
  };

  // Fonction pour activer la synth√®se vocale par un geste utilisateur
  const enableSpeech = useCallback(async () => {
    const voices = await waitForVoices();
    const frVoice = voices.find(v => v.lang.startsWith('fr')) || voices[0];
    if (!frVoice) {
      console.error("Aucune voix disponible pour la langue fran√ßaise.");
      return;
    }
    const utterance = new SpeechSynthesisUtterance("Bienvenue sur ClassifIA !");
    utterance.lang = 'fr-FR';
    utterance.voice = frVoice;

    speechSynthesis.cancel();
    setTimeout(() => {
      speechSynthesis.speak(utterance);
      console.log("üîä Lecture test r√©ussie avec :", frVoice.name);
    }, 100);

    setCanSpeak(true);
    console.log("‚úÖ Lecture vocale activ√©e.");
  }, []);

  // D√©clenchement de l'activation vocale d√®s le premier geste utilisateur
  useEffect(() => {
    const handleUserGesture = () => {
      if (!canSpeak) {
        enableSpeech();
      }
    };

    window.addEventListener("click", handleUserGesture, { once: true });
    window.addEventListener("keydown", handleUserGesture, { once: true });

    return () => {
      window.removeEventListener("click", handleUserGesture);
      window.removeEventListener("keydown", handleUserGesture);
    };
  }, [canSpeak, enableSpeech]);

  // Lecture vocale automatique lorsque la r√©ponse est g√©n√©r√©e
  // Attention : certains navigateurs bloquent l'auto lecture m√™me si la synth√®se est activ√©e.
  useEffect(() => {
    if (response && canSpeak) {
      speak(response);
    }
  }, [response, canSpeak]);

  const toggleDarkMode = () => {
    const newMode = !darkMode;
    setDarkMode(newMode);
    localStorage.setItem('classifia_dark', newMode.toString());
    document.body.classList.toggle('bg-dark', newMode);
    document.body.classList.toggle('text-light', newMode);
  };

  const classifyObject = async () => {
    const now = Date.now();
    if (lastCall && now - lastCall < COOLDOWN_MS) {
      alert("‚è≥ Attendez 10 secondes entre chaque requ√™te.");
      return;
    }
    if (requestCount >= MAX_REQUESTS) {
      alert("üö´ Limite de 30 requ√™tes atteinte.");
      return;
    }

    setLoading(true);
    setLastCall(now);
    setResponse('');
    setTrashImage(null);

    const newCount = requestCount + 1;
    setRequestCount(newCount);
    localStorage.setItem('gemini_request_count', newCount.toString());

    try {
      const res = await fetch(`${GEMINI_API_URL}?key=${GEMINI_API_KEY}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: [
            {
              parts: [
                {
                  text: `Dans quelle poubelle faut-il jeter cet objet : "${input}" ? R√©ponds de mani√®re claire avec le type de poubelle (ex : jaune, verte, marron...) et une explication simple.`
                }
              ]
            }
          ]
        })
      });

      const data = await res.json();
      const output = data.candidates?.[0]?.content?.parts?.[0]?.text;
      const finalResponse = output || "Aucune r√©ponse.";
      const imageUrl = getTrashImage(finalResponse);

      setResponse(finalResponse);
      setTrashImage(imageUrl);

      const newEntry = { object: input, result: finalResponse };
      const newHistory = [newEntry, ...history.slice(0, 9)];
      setHistory(newHistory);
      localStorage.setItem('classifia_history', JSON.stringify(newHistory));
    } catch (error) {
      setResponse("Erreur lors de la communication avec Gemini.");
    }

    setLoading(false);
  };

  const clearHistory = () => {
    setHistory([]);
    localStorage.removeItem('classifia_history');
  };

  return (
    <div className={`card p-4 shadow-sm ${darkMode ? 'bg-dark text-light' : ''}`}>
      <div className="d-flex justify-content-between align-items-center mb-3">
        <h4>Quel objet veux-tu jeter ?</h4>
        <button className="btn btn-sm btn-outline-secondary" onClick={toggleDarkMode}>
          {darkMode ? '‚òÄÔ∏è Mode clair' : 'üåô Mode sombre'}
        </button>
      </div>

      {/* Bouton explicite pour d√©bloquer la lecture vocale si n√©cessaire */}
      {!canSpeak && (
        <div className="mb-3">
          <button className="btn btn-warning" onClick={enableSpeech}>
            Activer la lecture vocale
          </button>
        </div>
      )}

      <div className="mb-2">
        {SUGGESTIONS.map((item, index) => (
          <button
            key={index}
            className="btn btn-outline-info btn-sm me-2 mb-2"
            onClick={() => setInput(item)}
          >
            {item}
          </button>
        ))}
      </div>

      <input
        type="text"
        className="form-control mb-3"
        placeholder="Ex : Bouteille de shampoing"
        value={input}
        onChange={(e) => setInput(e.target.value)}
      />

      <button
        className="btn btn-primary"
        onClick={classifyObject}
        disabled={loading}
      >
        {loading ? (
          <>
            <span className="spinner-border spinner-border-sm me-2"></span>
            Analyse en cours...
          </>
        ) : 'Classer avec l‚ÄôIA'}
      </button>

      {response && (
        <div className="alert alert-success mt-4 fade show">
          <strong>R√©sultat IA :</strong><br />{response}
          {/* Bouton pour relancer la lecture vocale, utile si l'auto lecture est bloqu√©e */}
          <button
            className="btn btn-outline-primary mt-3"
            onClick={() => speak(response)}
          >
            üîä Lire √† voix haute
          </button>
        </div>
      )}

      {trashImage && (
        <div className="text-center mt-3 fade show">
          <img src={trashImage} alt="Poubelle" style={{ maxWidth: '200px' }} />
          <p className="mt-2 text-muted">Poubelle correspondante</p>
        </div>
      )}

      <div className="mt-3 text-muted small text-end">
        Requ√™tes utilis√©es : {requestCount} / {MAX_REQUESTS}
      </div>

      {history.length > 0 && (
        <div className="mt-5">
          <div className="d-flex justify-content-between align-items-center mb-2">
            <h5>üïì Historique r√©cent</h5>
            <button className="btn btn-sm btn-outline-danger" onClick={clearHistory}>
              Effacer
            </button>
          </div>
          <ul className="list-group">
            {history.map((item, i) => (
              <li key={i} className="list-group-item">
                <strong>{item.object}</strong> ‚Üí {item.result}
              </li>
            ))}
          </ul>
        </div>
      )}
    </div>
  );
};

export default Classifier;
